# -*- coding: utf-8 -*-
"""HYPERPARAMETER_TUNING.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17zo3vtLMfhc_s4MVniJOG6ois0lq9Suj
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

from google.colab import drive
drive.mount('/content/drive',force_remount=True)

from sklearn import decomposition
from sklearn.preprocessing import StandardScaler
from sklearn import pipeline

df=pd.read_csv('3yearsmodelsupported.csv')

df.head()

df.drop('Unnamed: 0',axis=1,inplace=True)

df.head()

df.drop(['FTHG', 'FTAG','TOTAL_SCORE'],inplace=True,axis=1)

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

learning_rates = [0.001,0.01,0.05,0.1,0.2,0.5]
results_list = []

# Create the for loop 
for i in learning_rates:
    model = GradientBoostingClassifier(learning_rate=i)
    predictions = model.fit(X_train,y_train).predict(X_test)
    # Save the learning rate and accuracy score
    results_list.append([i, accuracy_score(y_test, predictions)])

# Gather everything into a DataFrame
results_df = pd.DataFrame(results_list, columns=['learning_rate', 'accuracy'])
print(results_df)

# Setting  the learning rates & accuracies list
learn_rates = np.linspace(0.01, 2, num=30)
accuracies = []

# Create the for loop
for learn_rate in learn_rates:
  	# Create the model, predictions & save the accuracies as before
    model = GradientBoostingClassifier(learning_rate=learn_rate)
    predictions = model.fit(X_train, y_train).predict(X_test)
    accuracies.append(accuracy_score(y_test, predictions))

   
plt.plot(learn_rates, accuracies)
plt.gca().set(xlabel='learning_rate', ylabel='Accuracy', title='Accuracy for different learning_rates')
plt.show()

# Create a Random Forest Classifier with specified criterion
rf_class = RandomForestClassifier(criterion='entropy')

# Create the parameter grid
param_grid = {'max_depth': [2,4,8,15], 'max_features': ['auto','sqrt']} 

# Create a GridSearchCV object
grid_rf_class = GridSearchCV(
    estimator=rf_class,
    param_grid=param_grid,
    scoring='roc_auc',
    n_jobs=4,
    cv=5,
    refit=True, return_train_score=True)
print(grid_rf_class)

Rfmodel=RandomForestClassifier(n_jobs=-1)

Rfmodel

param_grid={ 'n_estimators': [100,200,300,400,500,600,700,800,900,1000]
             'max_depth' : [1,2,3,4,5,7,9,11,13,15,17],
              'criterion' :['gini','entropy']
             'min_samples_split' :np.arange(2,4,1),
             'min_samples_leaf' : np.arange(2,12,2),
            }
            #aman

model=GridSearchCV(estimator=Rfmodel,
                  param_grid=param_grid ,
                  scoring='accuracy',
                   verbose=10 ,
                   n_jobs=-1,
                   cv=5)

import pandas as pd
df=pd.read_csv('3yearsmodelsupported.csv')

import pandas as pd
df=pd.read_csv('model_supported6.csv')

import xgboost as xgb
xg_cl = xgb.XGBClassifier(objective='binary:logistic')

param_grid={ 'n_estimators': [400,450,500],
             'max_depth' : [4,6],
            'learning_rate':[0.01,0.03,0.11],
             'min_samples_split' :[8,10,12],
             'colsample_bytree':[0.7,0.8,0.9],
             'reg_lambda':[0.02,0.04,0.06]
            }

import numpy as np

k=np.arange(0.01,0.2,0.02)

k

from sklearn.model_selection import  GridSearchCV

model=GridSearchCV(estimator=xg_cl,
                  param_grid=param_grid ,
                  scoring='accuracy',
                   verbose=10 ,
                   n_jobs=-1,
                   refit=True,
                   cv=5)

model.fit(X,y)

print(model.best_score_)
print (model.best_estimator_.get_params())

# See what type of object the best_estimator_ property is
print(type(grid_rf_class.best_estimator_))

# Create an array of predictions directly using the best_estimator_ property
predictions = grid_rf_class.best_estimator_.predict(X_test)

# Take a look to confirm it worked, this should be an array of 1's and 0's
print(predictions[0:5])

# Now create a confusion matrix 
print("Confusion Matrix \n", confusion_matrix(y_test, predictions))

# Get the ROC-AUC score
predictions_proba = grid_rf_class.best_estimator_.predict_proba(X_test)[:,1]
print("ROC-AUC Score \n", roc_auc_score(y_test, predictions_proba))

#best tuned variable
model.best_params_

shaktiman=model.best_estimator_



k=[]
xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=400, seed=123,max_depth=4,
                          learning_rate=0.3,n_jobs=-1,random_state=125,subsample=0.9,
                          gamma=0.02,reg_lambda=0.01,min_samples_leaf=8,max_features='auto',loss='exponential'
                          ,min_samples_split=10
                          )
y=accuracy_scor()
y.

RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=9, 
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False)

"""RANDOM SEARCH CV

min_samples_split = [2, 5, 10]
min_samples_leaf = [1, 2, 4]
max_features = ['auto', 'sqrt']
"""

param_grid={ 'n_estimators': np.arange(100,1000,100),
             'max_depth' : np.arange(1,10,1),
             'min_samples_split' :np.arange(2,4,1),
             'min_samples_leaf' : np.arange(2,8,2),
              'criterion' :['gini','entropy']
            }

# Create the parameter grid
param_grid = {'learning_rate': np.linspace(0.1, 2, 150), 'min_samples_leaf': list(range(20, 65))} 

# Create a random search object
random_GBM_class = RandomizedSearchCV(
    estimator = GradientBoostingClassifier(),
    param_distributions = param_grid,
    n_iter = 10,
    scoring='accuracy', n_jobs=4, cv = 5, refit=True, return_train_score = True)

# Fit to the training data
random_GBM_class.fit(X_train, y_train)

# Print the values used for both hyperparameters
print(random_GBM_class.cv_results_['param_learning_rate'])
print(random_GBM_class.cv_results_['param_min_samples_leaf'])
--------------------------------------------------------------------------
# Create the parameter grid
param_grid = {'max_depth': list(range(5,26)), 'max_features': ['auto' , 'sqrt']} 

# Create a random search object
random_rf_class = RandomizedSearchCV(
    estimator = RandomForestClassifier(n_estimators=80),
    param_distributions = param_grid, n_iter = 5,
    scoring='roc_auc', n_jobs=4, cv = 3, refit=True, return_train_score = True)

# Fit to the training data
random_rf_class.fit(X_train, y_train)

# Print the values used for both hyperparameters
print(random_rf_class.cv_results_['param_max_depth'])
print(random_rf_class.cv_results_['param_max_features'])

from sklearn.model_selection import RandomizedSearchCV
model=RandomizedSearchCV(estimator=Rfmodel,
                  param_distributions=param_grid ,
                  n_iter=10,
                  scoring='accuracy',
                   verbose=10 ,
                   n_jobs=-1,
                   cv=5)

model.fit(X,y)

print(model.best_score_)
print (model.best_estimator_.get_params())

from sklearn import decomposition
from sklearn.preprocessing import StandardScaler
from sklearn import pipeline

Rfmodel=RandomForestClassifier(n_jobs=-1)



"""BAYESIAN OPTIMIZATION"""

import matplotlib.pyplot as plt

importances = pd.Series(data=xg_cl.feature_importances_,
                        index= X_train.columns)

# Sort importances
importances_sorted = importances.sort_values()

# Draw a horizontal barplot of importances_sorted
importances_sorted.plot(kind='barh', color='lightgreen')
plt.title('Features Importances')
plt.show()

from matplotlib.pyplot import figure
figure(num=None, figsize=(40, 40), dpi=80, facecolor='w', edgecolor='k')
importances_sorted.plot(kind='barh', color='lightgreen')
plt.title('Features Importances')
plt.show()

# Instantiate the individual models
clf_knn = KNeighborsClassifier(5)
clf_lr = LogisticRegression(class_weight="balanced")
clf_dt = DecisionTreeClassifier(min_samples_leaf=3 , min_samples_split =9, random_state=500)

# Create and fit the voting classifier
clf_vote = VotingClassifier(
    estimators=[('knn', clf_knn), ('lr', clf_lr), ('dt', clf_dt)]
)
clf_vote.fit(X_train, y_train)


# Calculate the predictions using the voting classifier
pred_vote = clf_vote.predict(X_test)

# Calculate the F1-Score of the voting classifier
score_vote = f1_score(y_test,pred_vote)
print('F1-Score: {:.3f}'.format(score_vote))

# Calculate the classification report
report = classification_report(y_test,pred_vote)
print(report)

